---
title: "RIVERpkg"
author: "Yungil Kim"
output: 
  BiocStyle::html_document
date: "`r doc_date()`"
package: "`r pkg_ver('RIVERpkg')`"
abstract: >
  A probabilistic modeling framework that jointly analyzes personal genome and transcriptome data to estimate the probability that a variant has regulatory impact in that individual.
vignette: >
  %\VignetteIndexEntry{RIVERpkg}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

<a id="top"></a>

# Introduction 

`RIVERpkg` is an `R` package of a probabilistic modeling framework, called *RIVER (RNA-Informed Variant Effect on Regulation)*, that jointly analyzes personal genome (WGS) and transcriptome data (RNA-seq) to estimate the probability that a variant has regulatory impact in that individual. It is based on a generative model that assumes that genomic annotations, such as the location of a variant with respect to regulatory elements, determine the prior probability that variant is a functional regulatory variant, which is an unobserved variable. The functional regulatory variant status then influences whether nearby genes are likely to display outlier levels of gene expression in that person.

*RIVER* is a hierarchical Bayesian model that predicts the regulatory effects of rare variants by integrating gene expression with genomic annotations. The *RIVER* consists of three layers: a set of nodes $G = G_{1}, ..., G_{P}$ in the topmost layer representing $P$ observed genomic annotations over all rare variants near a particular gene, a latent binary variable $FR$ in the middle layer representing the unobserved funcitonal regulatory status of the rare variants, and one binary node $E$ in the final layer representing expression outlier status of the nearby gene. We model each conditional probability distribution as follows: 
$$ FR | G \sim Bernoulli(\psi), \psi = logit^{-1}(\beta^T, G) $$
$$E | FR \sim Categorical(\theta_{FR}) $$
$$ \beta_i \sim N(0, \frac{1}{\lambda})$$
$$\theta_{FR} \sim Beta(C,C)$$

with parameters $\beta$ and $\theta$ and hyper-parameters $\lambda$ and $C$.

Because $FR$ is unobserved, log-likelihood objective of *RIVER* over instances $n = 1, ..., N$,
$$
\sum_{n=1}^{N} log\sum_{FR_n= 0}^{1} P(E_n, G_n, FR_n | \beta, \theta),
$$
is non-convex. We therefore optimize model parameters via Expectation-Maximization (EM) as follows:

In the E-step, we compute the posterior probabilities ($\omega_n^{(i)}$) of the latent variables $FR_n$ given current parameters and observed data. For example, at the $i$-th iteration, the posterior probability of $FR_n = 1$ for the $n$-th instance is
$$
\omega_{1n}^{(i)} = P(FR_n = 1 | G_n, \beta^{(i)}, E_n, \theta^{(i)})
=\frac{P(FR_n = 1 | G_n, \beta^{(i)}) \cdotp P(E_n | FR_n = 1, \theta^{(i)})}{\sum_{FR_n = 0}^1 P(FR_n | G_n, \beta^{(i)}) \cdotp P(E_n | FR_n, \theta^{(i)})},
$$
$$\omega_{0n}^{(i)} = 1 - \omega_{1n}^{(i)}.$$

In the M-step, at the $i$-th iteration, given the current estimates $\omega^{(i)}$, the parameters ($\beta^{(i+1)*}$) are estimated as 
$$
\max_{\beta^{(i+1)}} \sum_{n = 1}^N \sum_{FR_n = 0}^1 log(P(FR_n | G_n, \beta^{(i+1)})) \cdotp \omega_{FR, n}^{(i)} - \frac{\lambda}{2}||\beta^{(i+1)}||_2,
$$
where $\lambda$ is an L2 penalty hyper-parameter derived from the Gaussian prior on $\beta$.
The parameters $\theta$ get updated as: 
$$
\theta_{s,t}^{(i+1)} = \sum_{n = 1}^{N} I(E_n = t) \cdotp \omega_{s,n}^{(i)} + C.
$$
where $I$ is an indicator operator, $t$ is the binary value of expression $E_n$, $s$ is the possible binary values of $FR_n$ and $C$ is a pseudo count derived from the Beta prior on \theta. The E- and M-steps are applied iteratively until convergence.

[Back to Top](#top)

# Quick Start

The purpose of this section is to give users a general sense of the package, including the components, what they do and some basic usage. We will briefly go over the main functions, see the basic operations and have a look at the outputs. Users may have a better idea after this section what functions are available, which one to choose, or at least where to seek help. More details are given in later sections.

First, we load the `RIVERpkg`:
```{r 'ultraQuick'}
library("RIVERpkg")
```

Our `RIVERpkg` has several functions supporting two main functions including `evaRIVER` and `appRIVER`, which we are about to show how to use them here. We load a set of data created beforehand for illustration. Users can either load their own data or use those saved in the workspace.
```{r}
data(simulated_features) # G: features from genomic annotations
data(simulated_outliers) # E: outlier status from expression data
data(simulated_N2pairs) # P: N2 pairs for evaluating models
```
Above three commands load three input data, `simulated_features` with continuous values of genomic features (defined as $G$ in the objective function), `simulated_outliers` with binary values of outlier status across samples (defined as $E$ in the objective function), and `simulated_N2pairs` with a list of N2 pairs containing pairs of examples with same rare variants in `data.frame` formats, from this saved R data archive. The first input data, `simulated_features`, consists of subject IDs, gene names, and feature values from genomic annotations including conservation scores like Gerp, chromatin states from chromHMM or segway, and other summary scores such as CADD and DANN.
```{r}
head(simulated_features)
```
The intances were selected based on two criteria: (1) any genes having at least one individual outlier in term of z-scores of expression and (2) any individuals having at least one rare variant within specific regions near each gene. In each instance, the feature values within regions of interest were aggreated into one summary statistics by applying relevant mathematical operations like max. Another input data, `simulated_outliers`, consistes of subject IDs, gene names, and binary indicators for outlier status as follows.
```{r}
head(simulated_outliers)
```
`simulated_N2pairs` consist of a list of two individuals having same rare variants near genes. More specifically, given each of targeted genes (second and fourth column) in each row, first column contains subject ID of 1st individual and third column contains subject ID of 2nd individual from N2 pairs having same rare variants near the genes like
```{r}
head(simulated_N2pairs)
```
The `simulated_N2pairs` is used for evaluating models. Note that the three input data are in the same order.

In further details of a list of genomic annotations used for constructing features and how to generate the features and outlier status, please refer to our publication [pre-print](http://biorxiv.org/content/early/2016/09/09/074443).

For evaluation, we hold out pairs of individuals at genes where only those two individuals shared the same rare variants. Except for the list of instances, we train *RIVER* with the rest of instances, compute the *RIVER* score (the posterior probability of having a functional regulatory variant given both WGS and RNA-seq data) from one individual, and assess the accuracy with respect to the second individual’s held out expression levels. Using this labeled test data, we evaluate the predictive accuracy of *RIVER* compared with a genomic annotation model (*GAM*) that uses genomic annotations alone, and observe a significant improvement by incorporating expression data. To do so, we simply use `evaRIVER`:
```{r}
rocSTAT <- evaRIVER(simulated_features, simulated_outliers, simulated_N2pairs)
```
"rocSTAT" is an object of class that contains all the relevant information necessary for generating ROC curves of the two models with AUC values and their p-value. 
```{r}
summary(rocSTAT)
```
We can visualize the ROC curves with AUC values by executing `plotAUC` function:
```{r}
plotAUC(rocSTAT)
```
Each ROC curve from either *RIVER* or *GAM* is computed by comparing the posterior probability given available data for the 1st individual with the outlier status of the 2nd individual in the list of held-out pairs.

To use posterior probabilities for prioritizing functional rare variants in any downstream analysis such as finding pathogenic rare variants in disease, you simply run `appRIVER` to obtain the posterior probabilities:
```{r}
outRIVER <- appRIVER(simulated_features, simulated_outliers)
```
`outRIVER` is an object of class that contains subject IDs, gene names, $P(FR = 1 | G)$, $P(FR = 1 | G, E)$, and `fitRIVER`, all the relevant information of the fitted *RIVER* for further use. 
```{r}
summary(outRIVER)
```
To observe how much we can obtain additional information on functional rare variants by integrating the outlier status of gene expression into *RIVER* in the following figure.
```{r}
plotPosteriors(outRIVER, simulated_outliers)
```
As shown in this figure, the integration of both genomic features and expression outliers indeed provide higher quantitative power for prioritizing functional rare variants. You can observe a few examples of pathogenic regulatory variants based on posterior probabilities from *RIVER* in our paper (http://biorxiv.org/content/early/2016/09/09/074443).

[Back to Top](#top)

# Two Main Functions

## Evaluation of *RIVER*

The function, `evaRIVER`, is to see how much we can gain additional information by integrating an outlier status of gene expression into integrated models. The prioritization of functional rare variants has difficulty in its evaluation especially due to no gold standard class of the functionality of rare variants. To come up with this limitation, we extract pairs of individuals for genes having same rare variants and hold them out for the evaluation. In other words, we train *RIVER* with all the instances except for those heldout pairs of individuals, calculate posterior probabilities of functional regulatory variants given genomic features and outlier status for the first individual, and compare the probabilities with the second individual's outlier status. You can simply observe how the entire steps of evaluating models including both *RIVER* and *GAM* proceed by using `evaRIVER` with `verbose=TRUE`.:

```{r}
rocSTAT <- evaRIVER(simulated_features, simulated_outliers, simulated_N2pairs, 
                    pseudoc=50, theta_init=matrix(c(.99, .01, .3, .7), nrow=2), 
                    costs=c(100, 10, 1, .1, .01, 1e-3, 1e-4), verbose=TRUE)
```
`evaRIVER` has two input data including features and outliers and four optional parameters including pseudo count, initial theta, a list of candidate $\lambda$, and verbose. For two input data, `simulated_features` should contain from left columns to right columns subject IDs, gene names, and aggregated genomic features and `simulated_outliers` should contain from left columns to right columns subject IDs, gene names, and outlier status. both input data should be matched in the same order. Most of optional parameters are set according to your input data. The `pseudoc` is a hyperparameter for estimating `theta`, parameters between an unobserved `FR` node and observed outlier `E` node. Lower `pseudoc` provides higher reliance on observed data. The `theta_init` is an initial set of theta parameters. From left to right, the elements are $P(E = 0 | FR = 0)$, $P(E = 1 | FR = 0)$, $P(E = 0 | FR = 1)$, and $P(E = 1 | FR = 1)$, respecitively. The `costs` are the list of candidate $\lambda$ for searching the best L2 penaly hyperparameter for both *GAM* and *RIVER*. For more information on optinoal paramters, see Appendix 5.1 for optional parameters and Appendix 5.2 for parameter stabilities across different initializations.

To train *RIVER* with training data (all instances except for the individual pairs), we first select best lambda value based on 10 cross-validation on training dataset via `glmnet`. You can see the selected $\lambda$ parameter at the first line of output. The initial paramters of $\beta$ in *RIVER* were set based on the estimated $\beta$ parameters from *GAM*. In each EM iteration, the `evaRIVER` reports both the top 10 % threshold of expected $P(FR = 1 | G, E)$ and norms of difference between previous and current estimates of parameters. The EM algorithm iteratively find best estimates of both $\beta$ and $\theta$ until it converges within the predefined tolerence of the norm ($0.001$ for both $\beta$ and $\theta$). After the estimates of paramters converge, `evaRIVER` reports AUC values from both models and its p-value of the difference between them.

[Back to Top](#top)

## Application of *RIVER*

The function, `appRIVER`, is to train *RIVER* (and *GAM*) with all instances and compute posterior probabilities of them for the future analyses (i.e. finding pathogenic rare variants in disease). Same as `evaRIVER`, this function also requires two input data, `simulated_features` and `simulated_outliers`, have three optional parameters you can set based on your data. 
```{r}
outRIVER <- appRIVER(simulated_features, simulated_outliers, pseudoc=50, 
                     theta_init=matrix(c(.99, .01, .3, .7), nrow=2), 
                     costs=c(100, 10, 1, .1, .01, 1e-3, 1e-4), verbose=TRUE)
```
Like the reported procedures from `evaRIVER`, we can recognize which $\lambda$ is set and variant top 10 % threshold of expected $P(FR = 1 | G, E)$ and norms of difference during each of EM iteractions. 

If you would like to observe estimated parameters associated with genomic features ($\beta$) and outliers ($\theta$), you can simply use `print` for the corresponding parameters of interest.
```{r}
print(outRIVER$fitRIVER$beta)
```
```{r}
print(outRIVER$fitRIVER$theta)
```
These parameters can be used for computing test posterior probabilities of new instances given their $G$ and $E$ for further analyses.

[Back to Top](#top)

# Basics

## Installation of `RIVERpkg`

`R` is an open-source statistical environment which can be easily modified to enhance its functionality via packages. `RIVERpkg` is a `R` package available via the [Bioconductor](https://www.bioconductor.org/packages/release/BiocViews.html#___Software) repository for packages. `R` can be installed on any operating system from [CRAN](https://cran.r-project.org/) after which you can install `RIVERpkg` by using the following commands in your `R` session:

```{r, eval = FALSE}
## try http:// if https:// URLs are not supported
source("https://bioconductor.org/biocLite.R")
biocLite("RIVERpkg")
```

[Back to Top](#top)

## Session Info
Here is the output of sessionInfo() on the system on which this document was compiled:

```{r}
## Session info
library('devtools')
options(width = 120)
session_info()
```

[Back to Top](#top)

## Asking for Help

As package developers, we try to explain clearly how to use our packages and in which order to use the functions. But `R` and `Bioconductor` have a steep learning curve so it is critical to learn where to ask for help. The blog post quoted above mentions some but we would like to highlight the [Bioconductor support site](https://support.bioconductor.org/) as the main resource for getting help. Other alternatives are available such as creating GitHub issues and tweeting. However, please note that if you want to receive help you should adhere to the [posting guidlines](http://www.bioconductor.org/help/support/posting-guide/). It is particularly critical that you provide a small reproducible example and your session information so package developers can track down the source of the error.

[Back to Top](#top)

## References

<p> Xin Li$^{*}$, Yungil Kim$^{*}$, Emily K. Tsang$^{*}$, Joe R. Davis$^{*}$, Farhan N. Damani, Colby Chiang, Zachary Zappala, Benjamin J. Strober, Alexandra J. Scott, Andrea Ganna, Jason Merker, GTEx Consortium, Ira M. Hall, Alexis Battle$^{\#}$, Stephen B. Montgomery$^{\#}$ (2016). <br>
<a href="http://biorxiv.org/content/early/2016/09/09/074443">The impact of rare variation on gene expression across tissues </a><br>
<i>(in arXiv, submitted, *: equal contribution, #: corresponding authors) </i></p>

[Back to Top](#top)

# Appendices

## Optional parameters
 
Functions within `RIVERpkg` have a set of optional parameters which control some aspects of the computation of *RIVER* scores. The *factory default* settings are expected to serve in many cases, but users might need to make changes based on the input data.

There are four parameters that users can change:

`pseudoc` - Pseudo count (hyperparameter) in a beta distribution for $\theta$; *factory default = 50* 

`theta_init` - Initial values of $\theta$; *factory default = (P(E = 0 | FR = 0), P(E = 1 | FR = 0), P(E = 0 | FR = 1), P(E = 1 | FR = 1)) = (0.99, 0.01, 0.3, 0.7)*

`costs` - List of candidate $\lambda$ values for finding a best $\lambda$ (hyperparameter). A best $\lambda$ value among the candidate list is selected from L2-regularized logistic regression (*GAM*) via 10 cross-validation; *factory default = (100, 10, 1, .1, .01, 1e-3, 1e-4)*

`verbose` - If you set this parameter as `TRUE`, you observe how parameters including $\theta$ and $\beta$ converge until their updates at each EM iteration are within predefined tolerance levels (one norm of the difference between current and previous parameters < 1e-3); *factory default = `FALSE`*

Note that initial values of $\beta$ are generated from L2-regularized logistic regression (*GAM*) with pre-selected $\lambda$ from 10 cross-validation.

[Back to Top](#top)

## Stability of Estimated Parameters with Different Parameter Initializations

In this section, we reports how several different initialization parameters for either $\beta$ or $\theta$ affect the estimated parameters. We initialized a noisy $\beta$ by adding K% Gaussian noise compared to the mean of $\beta$ with fixed $\theta$ (for K = 10, 20, 50 100, 200, 400, 800). For $\theta$, we fixed P(E = 1 | FR = 0) and P(E = 0 | FR = 0) as 0.01 and 0.99, respectively, and initialized (P(E = 1 | FR = 1), P(E = 0 | FR = 1)) as (0.1, 0.9), (0.4, 0.6), and (0.45, 0.55) instead of (0.3, 0.7) with $\beta$ fixed. For each parameter initialization, we computed Spearman rank correlations between parameters from *RIVER* using the original initialization and the alternative initializations. We also investigated how many instances within top 10% of posterior probabilities from *RIVER* under the original settings were replicated in the top 10% of posterior probabilities under the alternative initializations. We also tried five different values of pseudoc as 10, 20, 30, 75, and 100 with default settings of $\beta$ and $\theta$ and computed both Spearman rank correlations and accuracy as explained above.

| Parameter	| Initialization | Spearman ρ	| Accuracy |
|:----------:|---------------:|-----------:|----------:|
|         	|    10% noise	 |   > .999	  |  0.880   |
|         	|    25% noise	 |   > .999	  |  0.862   |
|         	|    50% noise	 |   > .999	  |  0.849   |
|  $\beta$	|    100% noise	 |   > .999	  |  0.848  | 
|         	|    200% noise	 |   > .999	  |  0.843   |
|         	|    400% noise	 |   > .999	  |  0.846   |
|         	|    800% noise	 |   > .999	  |  0.846   |
|         	|   [0.1, 0.9]   |   > .999	  |  0.841   |
| $\theta$	|   [0.4, 0.6]	 |   > .999	  |  1.000   |
|         	|  [0.45, 0.55]	 |   > .999	  |  1.000   |
|         	|    10	 |   .988	  |  0.934   |
|         	|    20	 |   .996	  |  0.955   |
| pseudoc	|    30	 |   .999	  |  0.972   |
|         	|    75	 |   .999	  |  0.979   |
|         	|  100	 |   .998	  |  0.967   |

[Back to Top](#top)
